% 若编译失败，且生成 .synctex(busy) 辅助文件，可能有两个原因：
% 1. 需要插入的图片不存在：Ctrl + F 搜索 'figure' 将这些代码注释/删除掉即可
% 2. 路径/文件名含中文或空格：更改路径/文件名即可

% ------------------------------------------------------------- %
% >> ------------------ 文章宏包及相关设置 ------------------ << %
% 设定文章类型与编码格式
\documentclass[UTF8]{report}		

% 本文特殊宏包
\usepackage{siunitx} % 埃米单位

% 本 .tex 专属的宏定义
    \def\V{\ \mathrm{V}}
    \def\mV{\ \mathrm{mV}}
    \def\kV{\ \mathrm{KV}}
    \def\KV{\ \mathrm{KV}}
    \def\MV{\ \mathrm{MV}}
    \def\A{\ \mathrm{A}}
    \def\mA{\ \mathrm{mA}}
    \def\kA{\ \mathrm{KA}}
    \def\KA{\ \mathrm{KA}}
    \def\MA{\ \mathrm{MA}}
    \def\O{\ \Omega}
    \def\mO{\ \Omega}
    \def\kO{\ \mathrm{K}\Omega}
    \def\KO{\ \mathrm{K}\Omega}
    \def\MO{\ \mathrm{M}\Omega}
    \def\Hz{\ \mathrm{Hz}}

% 自定义宏定义
    \def\N{\mathbb{N}}
    \def\F{\mathbb{F}}
    \def\Z{\mathbb{Z}}
    \def\Q{\mathbb{Q}}
    \def\R{\mathbb{R}}
    \def\C{\mathbb{C}}
    \def\T{\mathbb{T}}
    \def\S{\mathbb{S}}
    \def\A{\mathbb{A}}
    \def\I{\mathscr{I}}
    \def\Im{\mathrm{Im\,}}
    \def\Re{\mathrm{Re\,}}
    \def\d{\mathrm{d}}
    \def\p{\partial}

% 导入基本宏包
    \usepackage[UTF8]{ctex}     % 设置文档为中文语言
    \usepackage[colorlinks, linkcolor=blue, anchorcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}  % 宏包：自动生成超链接 (此宏包与标题中的数学环境冲突)
    % \usepackage{hyperref}  % 宏包：自动生成超链接 (此宏包与标题中的数学环境冲突)
    % \hypersetup{
    %     colorlinks=true,    % false:边框链接 ; true:彩色链接
    %     citecolor={blue},    % 文献引用颜色
    %     linkcolor={blue},   % 目录 (我们在目录处单独设置)，公式，图表，脚注等内部链接颜色
    %     urlcolor={orange},    % 网页 URL 链接颜色，包括 \href 中的 text
    %     % cyan 浅蓝色 
    %     % magenta 洋红色
    %     % yellow 黄色
    %     % black 黑色
    %     % white 白色
    %     % red 红色
    %     % green 绿色
    %     % blue 蓝色
    %     % gray 灰色
    %     % darkgray 深灰色
    %     % lightgray 浅灰色
    %     % brown 棕色
    %     % lime 石灰色
    %     % olive 橄榄色
    %     % orange 橙色
    %     % pink 粉红色
    %     % purple 紫色
    %     % teal 蓝绿色
    %     % violet 紫罗兰色
    % }

    % \usepackage{docmute}    % 宏包：子文件导入时自动去除导言区，用于主/子文件的写作方式，\include{./51单片机笔记}即可。注：启用此宏包会导致.tex文件capacity受限。
    \usepackage{amsmath}    % 宏包：数学公式
    \usepackage{mathrsfs}   % 宏包：提供更多数学符号
    \usepackage{amssymb}    % 宏包：提供更多数学符号
    \usepackage{pifont}     % 宏包：提供了特殊符号和字体
    \usepackage{extarrows}  % 宏包：更多箭头符号
    \usepackage{multicol}   % 宏包：支持多栏 
    \usepackage{graphicx}   % 宏包：插入图片
    \usepackage{float}      % 宏包：设置图片浮动位置
    %\usepackage{article}    % 宏包：使文本排版更加优美
    \usepackage{tikz}       % 宏包：绘图工具
    %\usepackage{pgfplots}   % 宏包：绘图工具
    \usepackage{enumerate}  % 宏包：列表环境设置
    \usepackage{enumitem}   % 宏包：列表环境设置
    \usepackage[all]{xy} % 宏包：xy图形
    \usepackage{tikz-cd} % 宏包：xy图形

% 文章页面margin设置
    \usepackage[a4paper]{geometry}
        \geometry{top=1in}
        \geometry{bottom=1in}
        \geometry{left=0.75in}
        \geometry{right=0.75in}   % 设置上下左右页边距
        \geometry{marginparwidth=1.75cm}    % 设置边注距离（注释、标记等）

% 定义 solution 环境
\usepackage{amsthm}
\newtheorem{solution}{Solution}
        \geometry{bottom=1in}
        \geometry{left=0.75in}
        \geometry{right=0.75in}   % 设置上下左右页边距
        \geometry{marginparwidth=1.75cm}    % 设置边注距离（注释、标记等）

% 配置数学环境
    \usepackage{amsthm} % 宏包：数学环境配置
    % theorem-line 环境自定义
        \newtheoremstyle{MyLineTheoremStyle}% <name>
            {11pt}% <space above>
            {11pt}% <space below>
            {}% <body font> 使用默认正文字体
            {}% <indent amount>
            {\bfseries}% <theorem head font> 设置标题项为加粗
            {：}% <punctuation after theorem head>
            {.5em}% <space after theorem head>
            {\textbf{#1}\thmnumber{#2}\ \ (\,\textbf{#3}\,)}% 设置标题内容顺序
        \theoremstyle{MyLineTheoremStyle} % 应用自定义的定理样式
        \newtheorem{LineTheorem}{Theorem.\,}
    % theorem-block 环境自定义
        \newtheoremstyle{MyBlockTheoremStyle}% <name>
            {11pt}% <space above>
            {11pt}% <space below>
            {}% <body font> 使用默认正文字体
            {}% <indent amount>
            {\bfseries}% <theorem head font> 设置标题项为加粗
            {：\\ \indent}% <punctuation after theorem head>
            {.5em}% <space after theorem head>
            {\textbf{#1}\thmnumber{#2}\ \ (\,\textbf{#3}\,)}% 设置标题内容顺序
        \theoremstyle{MyBlockTheoremStyle} % 应用自定义的定理样式
        \newtheorem{BlockTheorem}[LineTheorem]{Theorem.\,} % 使用 LineTheorem 的计数器
    % definition 环境自定义
        \newtheoremstyle{MySubsubsectionStyle}% <name>
            {11pt}% <space above>
            {11pt}% <space below>
            {}% <body font> 使用默认正文字体
            {}% <indent amount>
            {\bfseries}% <theorem head font> 设置标题项为加粗
           % {：\\ \indent}% <punctuation after theorem head>
            {\\\indent}
            {0pt}% <space after theorem head>
            {\textbf{#3}}% 设置标题内容顺序
        \theoremstyle{MySubsubsectionStyle} % 应用自定义的定理样式
        \newtheorem{definition}{}

%宏包：有色文本框（proof环境）及其设置
    \usepackage[dvipsnames,svgnames]{xcolor}    %设置插入的文本框颜色
    \usepackage[strict]{changepage}     % 提供一个 adjustwidth 环境
    \usepackage{framed}     % 实现方框效果
        \definecolor{graybox_color}{rgb}{0.95,0.95,0.96} % 文本框颜色。修改此行中的 rgb 数值即可改变方框纹颜色，具体颜色的rgb数值可以在网站https://colordrop.io/ 中获得。（截止目前的尝试还没有成功过，感觉单位不一样）（找到喜欢的颜色，点击下方的小眼睛，找到rgb值，复制修改即可）
        \newenvironment{graybox}{%
        \def\FrameCommand{%
        \hspace{1pt}%
        {\color{gray}\small \vrule width 2pt}%
        {\color{graybox_color}\vrule width 4pt}%
        \colorbox{graybox_color}%
        }%
        \MakeFramed{\advance\hsize-\width\FrameRestore}%
        \noindent\hspace{-4.55pt}% disable indenting first paragraph
        \begin{adjustwidth}{}{7pt}%
        \vspace{2pt}\vspace{2pt}%
        }
        {%
        \vspace{2pt}\end{adjustwidth}\endMakeFramed%
        }



% 外源代码插入设置
    % matlab 代码插入设置
    \usepackage{matlab-prettifier}
        \lstset{style=Matlab-editor}    % 继承 matlab 代码高亮 , 此行不能删去
    \usepackage[most]{tcolorbox} % 引入tcolorbox包 
    \usepackage{listings} % 引入listings包
        \tcbuselibrary{listings, skins, breakable}
        \newfontfamily\codefont{Consolas} % 定义需要的 codefont 字体
        \lstdefinestyle{MatlabStyle_inc}{   % 插入代码的样式
            language=Matlab,
            basicstyle=\small\ttfamily\codefont,    % ttfamily 确保等宽 
            breakatwhitespace=false,
            breaklines=true,
            captionpos=b,
            keepspaces=true,
            numbers=left,
            numbersep=15pt,
            showspaces=false,
            showstringspaces=false,
            showtabs=false,
            tabsize=2,
            xleftmargin=15pt,   % 左边距
            %frame=single, % single 为包围式单线框
            frame=shadowbox,    % shadowbox 为带阴影包围式单线框效果
            %escapeinside=``,   % 允许在代码块中使用 LaTeX 命令 (此行无用)
            %frameround=tttt,    % tttt 表示四个角都是圆角
            framextopmargin=0pt,    % 边框上边距
            framexbottommargin=0pt, % 边框下边距
            framexleftmargin=5pt,   % 边框左边距
            framexrightmargin=5pt,  % 边框右边距
            rulesepcolor=\color{red!20!green!20!blue!20}, % 阴影框颜色设置
            %backgroundcolor=\color{blue!10}, % 背景颜色
        }
        \lstdefinestyle{MatlabStyle_src}{   % 插入代码的样式
            language=Matlab,
            basicstyle=\small\ttfamily\codefont,    % ttfamily 确保等宽 
            breakatwhitespace=false,
            breaklines=true,
            captionpos=b,
            keepspaces=true,
            numbers=left,
            numbersep=15pt,
            showspaces=false,
            showstringspaces=false,
            showtabs=false,
            tabsize=2,
        }
        \newtcblisting{matlablisting}{
            %arc=2pt,        % 圆角半径
            % 调整代码在 listing 中的位置以和引入文件时的格式相同
            top=0pt,
            bottom=0pt,
            left=-5pt,
            right=-5pt,
            listing only,   % 此句不能删去
            listing style=MatlabStyle_src,
            breakable,
            colback=white,   % 选一个合适的颜色
            colframe=black!0,   % 感叹号后跟不透明度 (为 0 时完全透明)
        }
        \lstset{
            style=MatlabStyle_inc,
        }



% table 支持
    \usepackage{booktabs}   % 宏包：三线表
    %\usepackage{tabularray} % 宏包：表格排版
    %\usepackage{longtable}  % 宏包：长表格
    %\usepackage[longtable]{multirow} % 宏包：multi 行列


% figure 设置
\usepackage{graphicx}   % 支持 jpg, png, eps, pdf 图片 
\usepackage{float}      % 支持 H 选项
\usepackage{svg}        % 支持 svg 图片
\usepackage{subcaption} % 支持子图
\svgsetup{
        % 指向 inkscape.exe 的路径
       inkscapeexe = C:/aa_MySame/inkscape/bin/inkscape.exe, 
        % 一定程度上修复导入后图片文字溢出几何图形的问题
       inkscapelatex = false                 
   }

% 图表进阶设置
    \usepackage{caption}    % 图注、表注
        \captionsetup[figure]{name=图}  
        \captionsetup[table]{name=表}
        \captionsetup{
            labelfont=bf, % 设置标签为粗体
            textfont=bf,  % 设置文本为粗体
            font=small  
        }
    \usepackage{float}     % 图表位置浮动设置 
        % \floatstyle{plaintop} % 设置表格标题在表格上方
        % \restylefloat{table}  % 应用设置


% 圆圈序号自定义
    \newcommand*\circled[1]{\tikz[baseline=(char.base)]{\node[shape=circle,draw,inner sep=0.8pt, line width = 0.03em] (char) {\small \bfseries #1};}}   % TikZ solution


% 列表设置
    \usepackage{enumitem}   % 宏包：列表环境设置
        \setlist[enumerate]{
            label=\bfseries(\arabic*) ,   % 设置序号样式为加粗的 (1) (2) (3)
            ref=\arabic*, % 如果需要引用列表项，这将决定引用格式（这里仍然使用数字）
            itemsep=0pt, parsep=0pt, topsep=0pt, partopsep=0pt, leftmargin=3.5em} 
        \setlist[itemize]{itemsep=0pt, parsep=0pt, topsep=0pt, partopsep=0pt, leftmargin=3.5em}
        \newlist{circledenum}{enumerate}{1} % 创建一个新的枚举环境  
        \setlist[circledenum,1]{  
            label=\protect\circled{\arabic*}, % 使用 \arabic* 来获取当前枚举计数器的值，并用 \circled 包装它  
            ref=\arabic*, % 如果需要引用列表项，这将决定引用格式（这里仍然使用数字）
            itemsep=0pt, parsep=0pt, topsep=0pt, partopsep=0pt, leftmargin=3.5em
        }  

% 文章默认字体设置
    \usepackage{fontspec}   % 宏包：字体设置
        \setmainfont{STKaiti}    % 设置中文字体为宋体字体
        \setCJKmainfont[AutoFakeBold=3]{STKaiti} % 设置加粗字体为 STKaiti 族，AutoFakeBold 可以调整字体粗细
        \setmainfont{Times New Roman} % 设置英文字体为Times New Roman


% 其它设置
    % 脚注设置
    \renewcommand\thefootnote{\ding{\numexpr171+\value{footnote}}}
    % 参考文献引用设置
        \bibliographystyle{unsrt}   % 设置参考文献引用格式为unsrt
        \newcommand{\upcite}[1]{\textsuperscript{\cite{#1}}}     % 自定义上角标式引用
    % 文章序言设置
        \newcommand{\cnabstractname}{序言}
        \newenvironment{cnabstract}{%
            \par\Large
            \noindent\mbox{}\hfill{\bfseries \cnabstractname}\hfill\mbox{}\par
            \vskip 2.5ex
            }{\par\vskip 2.5ex}


% 各级标题自定义设置
    \usepackage{titlesec}   
    % chapter
        \titleformat{\chapter}[hang]{\normalfont\Large\bfseries\centering}{Chapter \thechapter }{10pt}{}
        \titlespacing*{\chapter}{0pt}{-30pt}{10pt} % 控制上方空白的大小
    % section
        \titleformat{\section}[hang]{\normalfont\large\bfseries}{\thesection}{8pt}{}
    % subsection
        %\titleformat{\subsubsection}[hang]{\normalfont\bfseries}{}{8pt}{}
    % subsubsection
        %\titleformat{\subsubsection}[hang]{\normalfont\bfseries}{}{8pt}{}

% 见到的一个有意思的对于公式中符号的彩色解释的环境
        \usepackage[dvipsnames]{xcolor}
        \usepackage{tikz}
        \usetikzlibrary{backgrounds}
        \usetikzlibrary{arrows,shapes}
        \usetikzlibrary{tikzmark}
        \usetikzlibrary{calc}
        
        \usepackage{amsmath}
        \usepackage{amsthm}
        \usepackage{amssymb}
        \usepackage{mathtools, nccmath}
        \usepackage{wrapfig}
        \usepackage{comment}
        
        % To generate dummy text
        \usepackage{blindtext}
        
        
        %color
        %\usepackage[dvipsnames]{xcolor}
        % \usepackage{xcolor}
        
        
        %\usepackage[pdftex]{graphicx}
        \usepackage{graphicx}
        % declare the path(s) for graphic files
        %\graphicspath{{../Figures/}}
        
        % extensions so you won't have to specify these with
        % every instance of \includegraphics
        % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
        
        % for custom commands
        \usepackage{xspace}
        
        % table alignment
        \usepackage{array}
        \usepackage{ragged2e}
        \newcolumntype{P}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}
        \newcolumntype{X}[1]{>{\RaggedRight\hspace*{0pt}}p{#1}}
        
        % color box
        \usepackage{tcolorbox}
        
        
        % for tikz
        \usepackage{tikz}
        %\usetikzlibrary{trees}
        \usetikzlibrary{arrows,shapes,positioning,shadows,trees,mindmap}
        % \usepackage{forest}
        \usepackage[edges]{forest}
        \usetikzlibrary{arrows.meta}
        \colorlet{linecol}{black!75}
        \usepackage{xkcdcolors} % xkcd colors
        
        
        % for colorful equation
        \usepackage{tikz}
        \usetikzlibrary{backgrounds}
        \usetikzlibrary{arrows,shapes}
        \usetikzlibrary{tikzmark}
        \usetikzlibrary{calc}
        % Commands for Highlighting text -- non tikz method
        \newcommand{\highlight}[2]{\colorbox{#1!17}{$\displaystyle #2$}}
        %\newcommand{\highlight}[2]{\colorbox{#1!17}{$#2$}}
        \newcommand{\highlightdark}[2]{\colorbox{#1!47}{$\displaystyle #2$}}
        
        % my custom colors for shading
        \colorlet{mhpurple}{Plum!80}
        
        
        % Commands for Highlighting text -- non tikz method
        \renewcommand{\highlight}[2]{\colorbox{#1!17}{#2}}
        \renewcommand{\highlightdark}[2]{\colorbox{#1!47}{#2}}
        
        % Some math definitions
        \newcommand{\lap}{\mathrm{Lap}}
        \newcommand{\pr}{\mathrm{Pr}}
        
        \newcommand{\Tset}{\mathcal{T}}
        \newcommand{\Dset}{\mathcal{D}}
        \newcommand{\Rbound}{\widetilde{\mathcal{R}}}

% >> ------------------ 文章宏包及相关设置 ------------------ << %
% ------------------------------------------------------------- %



% ----------------------------------------------------------- %
% >> --------------------- 文章信息区 --------------------- << %
% 页眉页脚设置

\usepackage{fancyhdr}   %宏包：页眉页脚设置
    \pagestyle{fancy}
    \fancyhf{}
    \cfoot{\thepage}
    \renewcommand\headrulewidth{1pt}
    \renewcommand\footrulewidth{0pt}
    \chead{}
    \lhead{}
    \rhead{}

%文档信息设置
\title{认知神经科学课程报告\\ Cognitive Neuroscience Final Report}
\author{苏冠豪\quad 伍昱衡 \quad 尹超 \quad 张硕 \quad 郑子辰 \\\footnotesize （按照姓氏首字母排序）\\ \footnotesize 中国科学院大学，北京 100049\\ \footnotesize University of Chinese Academy of Sciences, Beijing 100049, China \\\footnotesize https://github.com/cn2025666/UCAS2025CognitiveNeuralscience}
\date{\footnotesize \today}  % 设置日期为编译当天
% >> --------------------- 文章信息区 --------------------- << %
% ----------------------------------------------------------- %     


% 开始编辑文章

\begin{document}
\zihao{5}           % 设置全文字号大小

% --------------------------------------------------------------- %
% >> --------------------- 封面序言与目录 --------------------- << %
% 封面
    \maketitle\newpage  
    \pagenumbering{Roman} % 页码为大写罗马数字
    \thispagestyle{fancy}   % 显示页码、页眉等

% 序言
    \begin{cnabstract}\normalsize 
我们小组选择了\textbf{选题二：连续学习常见认知任务}，具体要求如下：

一、课题背景

人工智能在很多领域上处理特定任务的能力已经达到了人的平均水平，甚至远超人类。通常，衡量人工智能是否成功的一大准则就是判断其模仿人类学习的能力。在特定任务上，机器被给予真实世界或仿真模型中的大量数据用于训练以完成特定任务。但这一过程仅仅关注最终结果，而忽视了学习过程，因此也就不具备人类学习中一大重要特征，即能够灵活地切换需要完成的任务，又可以在训练过程中连续地积累知识和经验。世界是在发展和不断变化的，如果不能具备适应的能力，就很难被称为真正地拥有智能。然而，这样的强鲁棒性和当下主流机器学习（Machine Learning, ML）算法相矛盾，统计机器学习方法大多依赖于独立同分布数据假设，且需要预处理和筛选过、大量、均质化的数据样本进行学习。当数据发生变化或是样本空间增大时，ML 算法常常对新的任务无能为力，或是习得新任务后在先前学习的任务上表现不佳，这也被称为灾难性遗忘
（Catastrophic Forgetting）。为了应对非静态环境下连续出现的任务序列，研究者提出了被称为连续学习（Continual learning）或增量学习（Incremental learning）的方法范式。连续学习帮助模型持续地积累知识，避免灾难性遗忘的发生，使得模型在面临新的知识时无需从头开始训练。当学习的任务相互关联时，当前任务的学习可以帮助模型在每个后续任务上取得更好的性能，或令模型在以前的任务上表现更好，这两种现象被分别称为前向迁移和后向迁移。在本课题中，利用感兴趣的连续学习方法训练模型，比较采用连续学习方法与否的模型表现差异，并分析结果。若能对于现有连续学习方法进行改进，并能借鉴认知神经科学原理、现象的，将视观点的新颖性和深入程度获得额外加分。要求提交完整实现代码，该连续学习方法是否有受到生物智能的启发？如果有，介绍其中涉及的认知神经科学机制。思考人工智能模型连续学习方法和人类认知的异同。

二、数据

采用模拟生成的认知任务作为训练集。NeuroGym 是基于 OpenAI Gym 开发的神经科学任务开源 Python 工具箱，提供心理学和认知科学常见的行为范式用于人工智能模型的训练\cite{molano2022neurogym}。任务说明参考 Environments — neurogym
documentation。也可采用其他文献提出的认知任务模拟方式，如 20-Cog-tasks\cite{yang2019training}等。）


三、课题内容

（1）选择合适模型同时完成不少于10种认知任务，并给出模型的任务表现。评价指标应至少包含F1分数和MSE损失中的一种。

（2）采用不少于2种连续学习方法，分别完成认知任务的训练，记录模型在每个任务完成训练时的任务评分。在所有任务完成训练后，对比每一种连续学习训练方式和一般训练方式的任务表现差异。重点关注连续学习是否能有效避免灾难性遗忘，甚至产生前向或后向知识迁移等学习优势。

（3）在提交的报告中介绍连续学习的认知任务来源于何种认知实验，思考采用的连续学习方法和生物智能体学习方式之间的异同。连续学习后模型是否会更接近生物智能体？若能给出实验证据，例如激活表征、行为表现等，将额外加分。

（4）（可选）改进现有连续学习方法，以提升多任务的连续学习性能。

（5）（可选）考虑到 NEUROGYM 等工具仅提供了认知任务的简单模拟，其仿真实验过程与被试实际完成任务的过程存在诸多差异。改进先前用于训练模型的认知任务，使其更加接近现实世界的实验环境，并分析这种任务仿真形式的改变对模型性能的影响。

\newpage

四、小组分工

郑子辰
2023K8009925005 
zhengzichen23@berkeley.edu
第一部分代码书写运行，
PPT制作，上台展示

伍昱衡
2023K8009926010
wuyuheng23@mails.ucas.edu.cn
第一部分部分代码，PPT制作，报告撰写

张硕
2023K8009926029
zhangshuo233@mails.ucas.ac.cn
第三部分代码书写运行，
PPT制作，上台展示，报告撰写

苏冠豪
2023K8009926020
suguanhao@mails.ucas.ac.cn
第二部分代码书写运行，
PPT制作，上台展示，报告撰写

尹超
2023K8009926003
yinchao23@mails.ucas.ac.cn
第四部分代码书写运行，
PPT制作，上台展示，报告撰写和最终整合修改


五、代码呈现

    代码已上传至 GitHub，链接如下：
    
    \url{https://github.com/cn2025666/UCAS2025CognitiveNeuralscience}
\end{cnabstract}
    \addcontentsline{toc}{chapter}{序言} % 手动添加为目录


% 目录
\setcounter{tocdepth}{4}                % 目录深度（为1时显示到section）
\tableofcontents                        % 目录页
\addcontentsline{toc}{chapter}{目录}    % 手动添加此页为目录
\thispagestyle{fancy}                   % 显示页码、页眉等 

% 收尾工作
    \newpage    
    \pagenumbering{arabic} 

% >> --------------------- 封面序言与目录 --------------------- << %
% --------------------------------------------------------------- %


% --------------------------------------------------------------- %
% >> --------------------- Part 1: 基线环境下的认知任务与连续学习实验 --------------------- << %
\chapter{Part 1: 基线环境下的认知任务与连续学习实验}


\section{任务描述与评价指标}
本部分系统性地评估了三类循环神经网络（LSTM、GRU、CTRNN）在标准（理想化）认知任务环境下的表现。任务涵盖GoNogo、DelayComp、DMS（MatchSample）、AntiReach、ContextDM、MatchCat、Distractor、PairedAssoc、DualMatch、EconomicDM等10种典型认知任务，涉及工作记忆、抑制控制、决策等多种认知功能。

每个任务均有明确定义的输入输出结构。模型表现采用F1分数和MSE损失两项指标进行综合评价，F1分数衡量分类准确性，MSE反映回归误差。

\section{实验设置与流程}
\subsection{数据生成与环境配置}
所有任务均基于NeuroGym环境生成，输入数据无噪声，时间阶段（如fixation、delay、decision）均为固定时长。训练集和测试集独立采样，保证实验可复现性。

\subsection{模型与训练方法}
\begin{itemize}
    \item \textbf{LSTM\cite{hochreiter1997long}/GRU\cite{cho2014learning}/CTRNN\cite{beer1995dynamical}}: 代表性循环神经网络结构，具备不同的记忆与动态特性。
    \item \textbf{顺序学习（Sequential Learning）}: 按顺序依次训练多个任务，考察灾难性遗忘现象。
    \item \textbf{弹性权重固化（EWC）\cite{kirkpatrick2017overcoming}}: 通过对重要参数加以约束，缓解灾难性遗忘。
\end{itemize}


\subsection{模型训练流程}
\begin{enumerate}
    \item \textbf{单任务训练}: 每个模型分别在单一任务上训练，获得最优性能作为基线。
    \item \textbf{顺序多任务训练}: 按预设顺序依次训练多个任务，记录每个任务训练完成后的所有任务表现，考察灾难性遗忘。
    \item \textbf{弹性权重固化（EWC）}: 在顺序训练基础上，加入EWC正则项，缓解遗忘。
\end{enumerate}

\section{模型表现与分析}
\subsection{单任务表现：F1分数与MSE损失}
三类模型在10个认知任务上的单任务训练过程中的loss与平均F1分数变化与最终F1分数如图\ref{fig:part1_compare}和图\ref{fig:part1_loss}所示。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{assets/part1/change.png}
    \caption{三类模型在训练过程中的loss与平均F1变化对比}
    \label{fig:part1_compare}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{assets/part1/compare.png}
    \caption{三类模型在10种认知任务上的最终F1分数对比}
    \label{fig:part1_loss}
\end{figure}

可以看出，GRU在大多数任务上均能取得较高的F1分数，以及loss随着轮次的增加降低较快，CTRNN在部分任务（如AntiReach）表现略逊。

详细数值见表\ref{tab:baseline_scores_1}：
\begin{table}[H]
    \centering
    \caption{基线环境下各模型单任务F1分数（前5个任务）}
    \label{tab:baseline_scores_1}
    \begin{tabular}{lccccc}
        	oprule
        Task & AntiReach & ContextDM & DelayComp & MatchCat & MatchSample \\
        \midrule
        LSTM & 0.91 & 0.65 & 0.92 & 0.81 & 0.82 \\
        GRU & 0.89 & 0.62 & 0.90 & 0.79 & 0.80 \\
        CTRNN & 0.91 & 0.63 & 0.89 & 0.80 & 0.85 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{基线环境下各模型单任务F1分数（后5个任务）}
    \label{tab:baseline_scores_2}
    \begin{tabular}{lccccc}
        	oprule
        Task & Distractor & PairedAssoc & DualMatch & EconomicDM & GoNogo \\
        \midrule
        LSTM & 1.00 & 0.88 & 0.75 & 1.00 & 1.00 \\
        GRU & 1.00 & 1.00 & 0.80 & 1.00 & 1.00 \\
        CTRNN & 1.00 & 1.00 & 0.77 & 1.00 & 0.99 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{顺序学习与灾难性遗忘}

在顺序多任务训练中，模型在新任务学习后，先前任务的表现普遍下降，表现出灾难性遗忘。以“GoNogo $\to$ DelayComp $\to$ DMS”顺序为例，GoNogo任务的F1分数从1.00降至约0.30，遗忘现象显著。

如图\ref{fig:part1_forget}所示，展示了顺序学习过程中各任务F1分数的变化趋势，直观反映了灾难性遗忘现象。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/part1/forget.png}
    \caption{顺序多任务训练中各任务F1分数变化，体现灾难性遗忘}
    \label{fig:part1_forget}
\end{figure}

\subsection{EWC方法缓解遗忘效果}

引入EWC后，模型在新任务学习后对旧任务的遗忘程度明显减轻。EWC通过对重要参数加权正则，促使模型在适应新任务的同时保留对旧任务的记忆。

图\ref{fig:part1_ewc}展示了EWC方法下各任务F1分数的变化趋势，与普通顺序学习对比，遗忘现象得到有效缓解。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/part1/ewc.png}
    \caption{EWC方法下各任务F1分数变化，遗忘现象显著缓解}
    \label{fig:part1_ewc}
\end{figure}

\subsection{模型结构对连续学习的影响}
LSTM和GRU由于门控机制，在长时依赖和任务切换时表现出更好的稳定性。CTRNN在部分任务上更易遗忘，表明其表征能力有限。

\section{小结与展望}
在理想化的基线环境下，循环神经网络能够高效完成多种认知任务，但在顺序学习中普遍存在灾难性遗忘。EWC等连续学习方法可有效缓解遗忘，但仍有提升空间。后续章节将进一步探讨更真实环境下的模型表现及连续学习机制。

% --------------------------------------------------------------- %
% >> --------------------- Part 2: 不同连续性学习方法的性能比对 --------------------- << %
\chapter{Part 2: 不同连续性学习方法的性能比对}

\section{方法与实验设置}

\subsection{认知任务序列}

实验采用 NeuroGym 工具箱构建了以下四个连续任务，模型必须依次进行学习：

\begin{enumerate}
    \item \textbf{GoNogo-v0}：基础的反应抑制任务，考察快速决策能力。
    \item \textbf{AntiReach-v0}：非线性空间映射任务，要求输出与刺激相反的动作。
    \item \textbf{DelayComparison-v0}：时序逻辑任务，涉及对两个时间间隔分开的刺激强度的比较。
    \item \textbf{DelayMatchSample-v0 (DMS)}：工作记忆任务，要求在延迟期后匹配样本。
\end{enumerate}

\subsection{模型架构}
所有实验均统一使用单层 LSTM 网络：
\begin{enumerate}
    \item 输入层：33维（包含刺激特征与任务ID）。
    \item 隐藏层：128个神经元（负责时序信息整合与工作记忆维持）。
    \item 输出层：33维（动作空间）。
    \item 优化器：Adam (lr=0.001)。
\end{enumerate}

\subsection{连续学习策略}
以基线学习为对照，探究四种连续学习算法对抗灾难性遗忘的效果。
\begin{enumerate}
    \item Baseline (Fine-tuning)：无任何保护机制，直接在新任务上训练。作为衡量遗忘程度的下界。
    \item EWC (Elastic Weight Consolidation)\cite{kirkpatrick2017overcoming}：基于贝叶斯推断，利用 Fisher 信息矩阵估计参数对旧任务的重要性，在损失函数中添加二次惩罚项 
    $$ \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{curr}} + \frac{\lambda}{2} \sum_{i} F_i (\theta_i - \theta_{i,\text{old}})^2$$
    \item Online EWC\cite{schwarz2018progress}：针对长序列任务改进的 EWC，引入衰减因子（Decay=1.0）动态更新累积 Fisher 矩阵，旨在更高效地处理多阶段任务。
    \item Experience Replay (ER)\cite{chaudhry2019tiny}：维护一个极小的 Episodic Memory Buffer (Size=20)，在训练新任务时，随机抽取旧任务样本与新样本混合训练。模拟生物海马体的回放机制。
    \item A-GEM (Averaged Gradient Episodic Memory)\cite{chaudhry2018efficient}：不直接重放旧数据，而是利用旧数据计算参考梯度。若新任务梯度与参考梯度夹角超过90度（点积为负），则将新梯度投影到与旧梯度正交的方向，以此保证新任务的学习不增加旧任务的损失。
\end{enumerate}

\section{实验结果与分析}

\subsection{基线方法的灾难性遗忘}    
基线实验展示了神经网络在缺乏保护机制时的脆弱性。
任务1 (GoNogo) 在学习完任务2后，F1分数从 1.00 暴跌至 0.48，最终仅剩 0.46。
任务2在学习完任务3后，F1从 1.00 跌至 0.53。平均遗忘率高达 0.4253。
这证实了 SGD 优化算法在寻找新任务最优解时，不仅没有利用旧知识，反而破坏了旧任务在参数空间中的流形结构。

\subsection{正则化方法EWC}

\subsubsection{Standard EWC：约束失效}
EWC的表现甚至劣于基线。最终平均遗忘率高达 0.6097，最终平均性能仅为 0.4161。
这可能源于 Fisher 信息矩阵的对角近似在 LSTM 高度非凸的损失曲面上不再准确。
RNN的参数在时间步上共享，导致参数微小的变动会在时间维度上累积巨大的误差。
简单的对角 Fisher 矩阵无法捕捉参数间复杂的时序相关性，导致约束方向错误，未能保护关键权重。

\subsubsection{归一化的EWC}
在归一化 EWC 保护下，Task 1 最终维持在 0.8989。虽然在引入 Task 2 时有过短暂波动，但在后续阶段表现极其稳健。

同时出现了显著的后向迁移，任务一 (GoNogo)：Stage 2 为 0.8068，但到 Stage 4 提升至 0.8989。任务二 (AntiReach)：Stage 2 刚学完时为 0.6255，但在学完 Task 3 后提升至 0.6819。

这意味着模型在学习更复杂的时序比较（DelayComparison）时，其内部 LSTM 单元对“刺激检测”和“空间映射”的权重分配变得更加高效，这种由于新任务驱动而增强旧任务能力的现象，证明了连续学习可以实现知识的协同进化。

\subsubsection{Online EWC：压缩带来性能损失}
在连续学习实验中，Online EWC 虽然通过将所有历史任务的 Fisher 信息压缩至单一矩阵实现了恒定的空间开销，但相比 Standard EWC，其最终平均性能下降了约 10.05%（0.5644 vs 0.6649），平均遗忘率则上升了近 4倍。

Online EWC 采用递归合并策略更新 Fisher 矩阵。这种“压缩”操作在模型参数量有限（128维 LSTM）的情况下，会导致不同任务的参数敏感区在同一个矩阵中发生重叠。随着任务增加，Fisher 矩阵变得过于“平滑”或“稠密”，失去了对特定任务关键突触的精准保护，导致 Task 3 (DelayComp) 的遗忘率（0.1823）显著高于 Standard EWC。

Online EWC 仅参考上一阶段的权重。一旦中间任务（如 Task 2）学习不充分，错误的方向会被累积到全局约束中。Standard EWC 由于保留了各任务独立且完美的“初始锚点”，允许模型在多重约束的缝隙中寻找最优解，并诱发了更强的后向迁移效应。

\subsection{记忆回放方法ER}
在连续学习实验中，记忆回放方法（ER）通过维护一个小型的 Episodic Memory Buffer，有效地缓解了遗忘现象。实验结果表明，ER 在保持新任务学习能力的同时，能够有效地保留旧任务的知识。

具体而言，ER 在每个训练阶段随机抽取旧任务样本与新任务样本进行混合训练。这种策略不仅增强了模型对旧任务的记忆，还促进了新旧任务之间的知识迁移。

与基线方法相比，ER 显著降低了平均遗忘率（0.4253 vs 0.1823），同时保持了较高的任务性能。这表明，记忆回放机制能够有效地模拟生物大脑的学习过程，通过不断回顾旧知识来巩固记忆。

\subsubsection{标准ER方法}
回放方法体现了更好的平衡表现，任务1(GoNogo) 在整个四个阶段中始终保持 F1=1.00。
与 Online EWC 不同，ER 在学习后续任务（T2, T3, T4）时均能达到或接近 1.0 的初始性能，并在后续阶段保持高位（如 T2 最终保持在 0.838）。
即便 Buffer Size 仅为 20，ER 依然表现强劲。这表明对于低维认知的流形，只需极少量的真实样本就足以约束梯度方向，使其停留在多任务共享的解空间内。

\subsubsection{A-GEM方法}
A-GEM 的表现接近ER，最终平均性能 0.9073，平均遗忘率 0.1235。A-GEM 并没有直接优化旧任务损失，而是将其作为不等式约束。
结果显示，虽然它有效避免了遗忘（T1 最终 0.94），但相比 ER 的直接联合训练，其“保守”的梯度投影策略在任务切换时的适应速度稍慢，导致最终性能略低于 ER。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{assets/part2/5methods_F1.png}
    \caption{不同连续学习策略下顺序任务的F1变化曲线}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{assets/part2/F1_forget.png}
    \caption{不同连续学习策略下平均F1与遗忘度对比}
\end{figure}

\section{连续学习机制与生物智能}
\subsection{稳定性-可塑性权衡}
Baseline 代表纯粹的可塑性（快速遗忘），Online EWC代表过度的稳定性（无法学习）。我们可以通过改变Online EWC中的$\lambda$来更直观地反映该矛盾:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{assets/part2/balance.png}
    \caption{不同$\lambda$值下Online EWC的稳定性-可塑性权衡}
\end{figure}

而 Experience Replay 成功打破了这一僵局。它证明了ER是平衡两者的关键——生物大脑并非通过单纯锁定突触（EWC方式）来记忆，而是通过海马体在睡眠或休息时对过往经历的重放（Replay）来巩固皮层记忆。我们的 ER 模型在计算上模拟了这一过程。

\subsection{知识迁移}
连续学习的目标不仅在于抑制灾难性遗忘，还在于实现跨任务的知识迁移。本文从前向知识迁移和后向知识迁移两个方面对实验结果进行分析。

实验结果表明，Experience Replay（ER）与 A-GEM 在新任务引入阶段具有更高的初始性能和更快的收敛速度，体现出显著的前向迁移能力。早期任务中形成的刺激感知与决策表征被成功复用于后续更复杂的时序与工作记忆任务，从而降低了新任务的学习难度。

同时，在归一化 EWC 与 ER 方法中观察到了明显的后向迁移现象。随着后续任务的学习，部分早期任务的性能不降反升，说明复杂时序任务促使 LSTM 学习到更稳定、高效的内部状态表示，这些改进后的表征反向提升了旧任务的判别与决策能力。相比之下，Online EWC 由于过度压缩参数重要性，限制了表征重组，几乎未产生后向迁移。

综上，具备有效知识迁移能力的连续学习方法，能够在保持旧知识稳定性的同时促进共享表征的持续优化，使学习过程呈现累积增强而非零和竞争的特性。

\section{结论}
本研究通过对比五种训练方案，系统评估了连续学习算法在认知任务序列上的有效性。主要结论如下：
\begin{enumerate}
    \item 灾难性遗忘是必然的：在没有任何干预的情况下，LSTM 无法在顺序学习中保留旧知识。
    \item 正则化方法的局限性：在循环神经网络中，简单的参数正则化（EWC）难以平衡稳定性与可塑性。
    \item 情景记忆回放是最优解：Experience Replay (ER) 是目前解决序列认知任务遗忘问题的最有效手段。它不仅以极小的存储代价（Buffer=20）实现了近乎零的遗忘，还保证了对新任务的高效学习。
    \item A-GEM 的潜力：作为一种不直接暴露旧数据的梯度约束方法，A-GEM 提供了接近 ER 的性能，在对数据隐私敏感的场景下具有应用价值。
\end{enumerate}

% --------------------------------------------------------------- %
% >> --------------------- Part 4: 生物学启发的连续学习模型 --------------------- << %


\chapter{Part 3: 生物学启发的连续学习模型}

根据先前对已有连续学习模型的研究与我们对神经科学知识的了解，在这部分中我们尝试构建两种合理的连续学习模型。

该部分使用的数据集以及随机数种子与先前实验相同，这样排除了偶然性，保证了实验可复现。

\section{基线实验结果展示}

我们选择连续学习效果较差的LSTM模型作为基线对照，改进的模型以LSTM为基本分类器。以下三图展示了该模型连续学习的效果。

从图 \ref{fig:simple_task2losses} 能了解模型每一轮任务的训练速度，图 \ref{fig:simple_task2f1} 和图 \ref{fig:simple_task2f1_matrix} 展示的信息是相同的，都是模型每轮学习后在所有任务上的性能，其中图 \ref{fig:simple_task2f1} 从上到下、从左到右每张图是对应轮次训练后的结果，一张图是同一训练阶段的模型对10个任务的测试结果。

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/simple_task2losses.png}
    \caption{经典LSTM神经网络连续学习10轮选定任务过程中的损失变化}
    \label{fig:simple_task2losses}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/simple_task2f1.png}
    \caption{经典LSTM神经网络连续学习10轮选定任务过程中模型每轮对所有任务测试的F1变化}
    \label{fig:simple_task2f1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/simple_task2f1_matrix.png}
    \caption{经典LSTM神经网络连续学习10轮选定任务过程中的F1矩阵}
    \label{fig:simple_task2f1_matrix}
\end{figure}

\section{模型构建思路}

\begin{enumerate}
    \item 模仿人类在持续学习过程中对于特定任务查找、联想并复习相关知识的习惯（经验表明人类这样的学习方式对于知识的归纳和组织的效果很好），在一般的非连续学习模型的新数据训练步骤中加入模型“复习”旧数据的过程。
    \item 基于大脑新皮层覆盖旧皮层的类似机制（处理旧任务的模型并不会在新模型迭代中消失，而是相互整合），模型可以主动对任务类型进行区分，在学习过程中不断新建用来处理自我分类的问题的子模型，并将子模型整合到主模型中。
\end{enumerate}

\section{相似性加权交错学习模型（SWIL）}

\subsection{模型结构描述}

类似学生对旧的相似知识的“复习”。把模型权重参数整体视为一个参数空间，假设每一轮训练数据学习对参数空间中参数点的作用是线性的，参数点被柔性限制在几个方向构成的子空间内（类似罚函数机制），在补空间内不移动或移动很少，可以认为子空间特征向量方向对旧任务是关键的，新的学习鼓励改变补空间方向的参数点移动，惩罚子空间方向的参数点移动，为了限制子空间方向移动，在新的训练数据中加入与新数据（特征层的权重参数的余弦）相似度较大的旧数据一起训练，起到用旧数据限制旧任务主导参数方向的作用。

这个连续学习方法已有类似先例，称为相似性加权交错学习（SWIL），本实验构建该模型的理念基本与之相同，但具体的细节是自主实现的。

\subsection{实验结果与分析}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/SWIL_task2losses.png}
    \caption{SWIL连续学习模型在10轮选定任务训练过程中的损失变化}
    \label{fig:SWIL_task2losses}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/SWIL_task2f1.png}
    \caption{SWIL连续学习模型在10轮选定任务训练过程中模型每轮对所有任务测试的F1变化}
    \label{fig:SWIL_task2f1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/SWIL_task2f1_matrix.png}
    \caption{SWIL连续学习模型在10轮选定任务训练过程中的F1矩阵}
    \label{fig:SWIL_task2f1_matrix}
\end{figure}

从这些图中可以看到，SWIL模型连续学习的速度和经典模型差不多，但学习效果提高显著。

事实上，与经典模型的训练过程相比，SWIL模型在学习时间上近似于经典模型学习新数据加少量旧数据所花的时间，在模型性能上近似于经典模型学习了所有历史数据（新数据和所有旧数据）后的性能。

\section{分层混合专家模型（HME）}

\subsection{模型结构描述}

人类在处理某个问题时，会先了解这个问题属于哪种任务（或是其他类似的手段），然后自主选择相关的知识解决这个问题。

模型也可以模仿这种思路：整个模型包括一个判断任务类型的一级分类器和若干个次级分类器。模型循环接收新任务的训练集和之前学的任务的测试集：训练过程中，模型先用每一个次级分类器对训练数据的一部分进行测试，得到若干个评估指标f1。如果所有f1都低于一个阈值，就加一个次级分类器，用训练数据来训练这个新分类器，一级分类器的应分类数量增加一个，删除原来的一级分类器，用事先存储的过去（包括本轮）问题和对应任务类型的信息来训练一个新实例化的一级分类器；如果至少存在一个f1高于阈值，取f1最大的那个次级分类器，用训练数据继续训练这个次级分类器，同样重新训练一个一级分类器。每轮循环的结尾进行测试和评估。

事实上，这种模型架构是当前连续学习研究的热点，由于理论基础不完善，模型仍有很多缺陷：(1)连续学习过程中需要假设数据流的每一组任务数据属于同一任务类型。(2)模型训练过程中次级分类器不断增加，这可能会违反连续学习的内存有限性要求，只能假设随着模型学习的任务增加，模型趋向于把新任务归类为旧任务，迭代过程中任务数收敛。(3)每一轮学习的一级分类器都需要重新训练，这样对算力要求高，训练效率低，同时要求存储过去问题和对应任务类型的信息，但内存不能没有上限，初步的解决思路是随机丢弃问题信息，这样的模型遗忘是必然的，无法实现真正的连续学习。

\subsection{实验结果与分析}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/HME_task2losses.png}
    \caption{HME连续学习模型在10轮选定任务训练过程中的损失变化}
    \label{fig:HME_task2losses}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/HME_task2f1.png}
    \caption{HME连续学习模型在10轮选定任务训练过程中模型每轮对所有任务测试的F1变化}
    \label{fig:HME_task2f1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/part3/HME_task2f1_matrix.png}
    \caption{HME连续学习模型在10轮选定任务训练过程中的F1矩阵}
    \label{fig:HME_task2f1_matrix}
\end{figure}

从这些图中可以看到，在前文描述的这些假设下实现的HME模型，连续学习的性能非常好，灾难性遗忘的频率降低，遗忘时间大幅拉长。在训练时间方面，HME模型两层分类器和多次级分类器的架构对算力的要求很高，每轮训练需要的时间长，损失收敛需要的epoch数也很长，受限于网络深度以及学习率（训练时间过长不允许低学习率精确找到最优），损失常会出现收敛至较高值的情况。

要实现真正可用于连续学习的HME模型，还需要用许多精巧的手段去除这些假设，同时降低模型的计算复杂度，提高模型的学习效率。目前组内探索但未实现的模型改进策略有：

\begin{enumerate}
    \item 使用多种方法综合评估任务数据集之间的相似度，而非简单地计算次级分类器对任务数据的分类效果（f1值）
    \item 加深基础神经网络的层数和维数，提高模型的表达能力
    \item 将一级分类器改为连续分类模型（即输入是问题，输出为问题类型的概率分布），解决一级分类器不断更新需要占用算力的问题
    \item 将原本存储“例题”数据用于一级分类器训练的机制改为训练一个问题关联问题类型数据的生成器，使用生成器的生成数据训练一级分类器，避免存储过多的“例题”数据
\end{enumerate}

% --------------------------------------------------------------- %
% >> --------------------- Part 5: 真实环境下的认知任务仿真与分析 --------------------- << %


\chapter{Part 4: 真实环境下的认知任务仿真与分析}

\section{改进思路与生物学启发}

考虑到 NeuroGym 等工具提供的认知任务通常是在理想化条件下进行的（无噪声、固定时间间隔），这与生物体在现实世界中面临的环境存在显著差异。为了更深入地探究人工智能模型与生物智能的异同，我们在本部分对实验环境进行了两项关键改进，旨在模拟更真实的生物认知环境。

\subsection{引入感知噪声 (Sensory Noise)}
现实世界中的感官输入永远不是完美的，总是伴随着噪声。生物神经系统本身也充满了噪声，例如突触传递的随机性和感觉器官的固有噪声。然而，大脑能够通过群体编码（Population Coding）和吸引子动力学（Attractor Dynamics）等机制，在充满噪声的环境中维持稳定的表征。

我们在模型接收的观测数据中添加了高斯噪声（Gaussian Noise, $\sigma=0.2$）。这一改进旨在测试模型是否不仅仅是拟合了干净的数据，而是学习到了鲁棒的神经表征，能够像生物大脑一样从嘈杂的输入中提取有效信息。

\subsection{引入时间变异性 (Temporal Variability)}
在标准的认知实验模拟中，刺激呈现（Fixation）、延迟（Delay）和决策（Decision）的时间通常是固定的。然而，在自然环境中，事件的时间进程往往具有高度的不确定性。生物体的前额叶皮层（PFC）和海马体被认为在跨越不确定时间间隔维持工作记忆方面起着关键作用。

我们将任务中的关键时间阶段从固定时长改为在一定范围内随机采样（Uniform Distribution）。例如，延迟阶段不再是固定的 500ms，而是在 [200ms, 1000ms] 之间随机变化。这迫使模型学习更通用的动力学机制（如神经积分器或持续活动），而不是简单地通过“计数”固定的时间步来解决任务。

\section{代码实现}

为了实现上述改进，我们编写了 \texttt{realistic\_experiment.py}。以下是核心代码片段，展示了如何构建具有时间变异性的环境以及如何注入感知噪声。

\begin{lstlisting}[style=MatlabStyle_inc, caption={真实环境构建与噪声注入代码片段}]
# 1. 定义时间变异性参数
timing_kwargs = {
    'timing': {
        'fixation': ('uniform', [100, 300]), # 注视期随机化
        'delay': ('uniform', [200, 1000]),   # 延迟期大幅随机化
        'decision': ('uniform', [200, 600])  # 决策期随机化
    }
}
sigma_noise = 0.2 # 噪声标准差

# 2. 环境初始化与噪声注入
def get_batch(task_idx, batch_size=16, seed_offset=0):
    # ... (省略部分代码)
    # 使用 numpy 的随机状态来生成噪声，确保可复现
    rng = np.random.RandomState(task_idx * 1000 + seed_offset)

    for b in range(batch_size):
        obs, _ = env.reset(seed=task_idx * 1000 + seed_offset + b)
        for t in range(MAX_SEQ_LEN):
            # 手动添加高斯噪声
            noise = rng.normal(0, sigma_noise, size=obs.shape)
            batch_obs[b, t, :obs.shape[0]] = obs + noise
            
            # ... (环境步进)
\end{lstlisting}

\section{实验结果与分析}

\subsection{环境复杂度对模型性能的影响}

我们在改进后的“真实环境”中重新训练并评估了 LSTM, GRU, CTRNN 三种模型。图 \ref{fig:realistic_comparison} 展示了三种模型在 10 个认知任务上的 F1 分数对比。

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/realistic_comparison.png}
    \caption{真实环境（噪声+可变时间）下三种模型的性能对比}
    \label{fig:realistic_comparison}
\end{figure}

为了更直观地展示环境变化带来的影响，我们将 Part 1（基线环境）与 Part 5（真实环境）的性能进行了直接对比，如图 \ref{fig:impact_analysis} 所示。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/impact_analysis.png}
    \caption{基线环境与真实环境的模型性能差异分析}
    \label{fig:impact_analysis}
\end{figure}

从图中可以观察到：
\begin{enumerate}
    \item \textbf{普遍性能下降}：引入噪声和时间不确定性后，所有模型的性能在大多数任务上都出现了下降。特别是 \texttt{AntiReach} 和 \texttt{ContextDM} 等任务，受噪声影响较为严重。
    \item \textbf{模型鲁棒性差异}：LSTM 和 GRU 凭借其门控机制（Gating Mechanisms），在处理长时程依赖和噪声干扰方面表现出比 CTRNN 更好的鲁棒性。CTRNN 在 \texttt{AntiReach} 任务上的 F1 分数下降最为显著（从 0.91 降至 0.25），表明简单的循环神经网络难以在强噪声下维持精确的运动轨迹预测。
    \item \textbf{部分任务的适应性}：值得注意的是，在 \texttt{GoNogo} 和 \texttt{EconomicDM} 等任务上，模型依然保持了接近满分的表现，说明这些任务的核心特征较为显著，不易受环境扰动影响。
\end{enumerate}

表 \ref{tab:realistic_scores} 详细列出了三种模型在真实环境下的具体 F1 分数。

\begin{table}[H]
    \centering
    \caption{真实环境下各模型 F1 分数汇总}
    \label{tab:realistic_scores}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{lcccccccccc}
        \toprule
        Task & AntiReach & ContextDM & DelayComp & MatchCat & MatchSample & Distractor & PairedAssoc & DualMatch & EconomicDM & GoNogo \\
        \midrule
        LSTM & 0.77 & 0.43 & 0.81 & 0.65 & 0.65 & 1.00 & 0.72 & 0.59 & 1.00 & 0.99 \\
        GRU & 0.65 & 0.38 & 0.77 & 0.57 & 0.67 & 1.00 & 1.00 & 0.67 & 1.00 & 0.99 \\
        CTRNN & 0.25 & 0.41 & 0.74 & 0.58 & 0.79 & 1.00 & 0.99 & 0.59 & 1.00 & 0.96 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{真实环境对灾难性遗忘的影响}

我们进一步探究了环境复杂度对连续学习中“灾难性遗忘”现象的影响。我们复现了 Part 1 中的顺序学习实验（Task 1: GoNogo $\to$ Task 2: DelayComp $\to$ Task 3: DMS），并对比了基线环境和真实环境下的遗忘曲线。

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{assets/forgetting_comparison.png}
    \caption{基线环境与真实环境下的灾难性遗忘对比}
    \label{fig:forgetting_comparison}
\end{figure}

如图 \ref{fig:forgetting_comparison} 所示，我们观察到了一个非常有趣的现象：

\begin{itemize}
    \item \textbf{基线环境 (Baseline)}: Task 1 (GoNogo) 在学习后续任务后，F1 分数经历了剧烈的下降，从 1.00 跌至约 0.30，表现出严重的灾难性遗忘。
    \item \textbf{真实环境 (Realistic)}: 虽然 Task 1 的初始学习性能略低（约 0.97），但在学习后续任务后，其 F1 分数维持在约 0.53。相比基线环境，\textbf{遗忘程度得到了缓解}（性能下降幅度更小）。
\end{itemize}

\textbf{分析与讨论}：
这一结果表明，\textbf{噪声和时间变异性可能起到了类似“正则化”（Regularization）的作用}。在理想化的基线环境中，模型可能倾向于利用简单的、非鲁棒的特征（Shortcut Learning）来快速解决任务，这些特征在任务切换时极易被覆盖。而在充满噪声和不确定性的真实环境中，模型被迫学习更本质、更鲁棒的特征表示（例如更稳定的吸引子状态或更通用的时间积分机制）。这些鲁棒的特征在面临新任务的干扰时表现出了更强的稳定性，从而在一定程度上减轻了灾难性遗忘。这一发现与认知神经科学中关于“噪声在神经计算中的积极作用”的观点相呼应，也为改进连续学习算法提供了新的思路。




\chapter{总结陈述}

本研究围绕“连续学习常见认知任务”这一核心课题，从基线模型性能评估、连续学习算法对比、生物启发式模型构建以及真实环境仿真四个维度展开了系统性的探索。通过一系列实验与分析，我们得出以下主要结论：

\section{主要发现}

\begin{enumerate}
    \item \textbf{灾难性遗忘是人工神经网络面临的严峻挑战}：
    在Part 1的基线实验中，我们证实了LSTM、GRU和CTRNN等循环神经网络虽然在单任务上表现优异，但在顺序学习过程中均表现出严重的灾难性遗忘现象。新知识的获取往往以旧知识的覆盖为代价，这与生物智能体具备的终身学习能力形成了鲜明对比。

    \item \textbf{情景记忆回放（Experience Replay）是当前最有效的抗遗忘机制}：
    在Part 2的算法对比中，我们发现基于记忆回放的方法（ER）显著优于参数正则化方法（EWC、Online EWC）。ER通过维护极少量的旧任务样本（Buffer=20）并在训练中重放，成功打破了“稳定性-可塑性”的僵局，不仅实现了近乎零的遗忘，还促进了前向和后向的知识迁移。这一发现有力地支持了海马体在生物记忆巩固中的关键作用——即通过神经重放（Replay）将短期记忆转化为皮层长期记忆。

    \item \textbf{生物启发式结构为连续学习提供了新思路}：
    在Part 3中，我们构建了相似性加权交错学习（SWIL）模型和分层混合专家（HME）模型。SWIL通过模拟人类“复习”相似知识的习惯，有效提升了学习效果；HME则模仿大脑皮层的功能分区与层级结构，通过动态扩展子模型来适应新任务。尽管HME面临计算复杂度高的挑战，但其“分而治之”的策略为解决任务干扰提供了结构化的视角。

    \item \textbf{环境噪声与不确定性具有正则化效应}：
    在Part 4的真实环境仿真中，我们引入了感知噪声和时间变异性。实验结果表明，虽然环境复杂度的增加导致了模型单任务性能的普遍下降，但在连续学习过程中，这种“真实”的训练环境反而促使模型学习到了更鲁棒的特征表示，从而在一定程度上缓解了灾难性遗忘。这一反直觉的发现提示我们，生物智能的鲁棒性可能正是演化过程中为了适应嘈杂环境而产生的副产物，单纯追求理想环境下的高精度拟合可能不利于通用智能的形成。
\end{enumerate}

\section{综合展望}

综上所述，本课题不仅验证了现有连续学习方法的有效性，更深入探讨了其背后的神经科学机制。我们的研究表明，要构建真正具备连续学习能力的人工智能，不能仅依赖单一的算法改进，而应从\textbf{突触可塑性（EWC）}、\textbf{系统级记忆巩固（ER/海马体）}、\textbf{动态网络结构（HME/皮层）}以及\textbf{环境适应性（真实环境仿真）}等多个层面进行跨尺度的协同设计。

未来的工作将致力于结合生成式模型实现“伪排练”（Pseudo-rehearsal）以摆脱对真实数据的存储依赖，并进一步探索脉冲神经网络（SNN）在低能耗连续学习中的潜力，向着更接近生物智能的终身学习系统迈进。





% ----------------------------------------------------------- %
% >> ---------------------- 参考文献 ---------------------- << %
\nocite{*}
\bibliography{re}
\thispagestyle{fancy} 
\addcontentsline{toc}{chapter}{参考文献}
%这里要用到 bibtex，使用xelatex->bibtex->xelatex->xelatex编译链
%同时要把re.bib文件放在同一目录下
%下面是re.bib文件的内容
% @book{knuth1984texbook,
%   author    = {Donald E. Knuth},
%   title     = {The TeXbook},
%   year      = {1984},
%   publisher = {Addison-Wesley},
% }

% @article{lamport1994latex,
%   author  = {Leslie Lamport},
%   title   = {LaTeX: A Document Preparation System},
%   journal = {Addison-Wesley},
%   year    = {1994},
% }

% @inproceedings{goossens1993latex,
%   author    = {Michel Goossens and Frank Mittelbach and Alexander Samarin},
%   title     = {The LaTeX Companion},
%   booktitle = {Addison-Wesley Series on Tools and Techniques for Computer Typesetting},
%   year      = {1993},
% }

% @misc{wikibibtex,
%   author       = {Wikipedia contributors},
%   title        = {BibTeX --- Wikipedia{,} The Free Encyclopedia},
%   year         = {2024},
%   url          = {https://en.wikipedia.org/wiki/BibTeX},
%   note         = {Accessed: 2025-04-15}
% }



% >> ---------------------- 参考文献 ---------------------- << %
% ----------------------------------------------------------- %



% ------------------------------------------------------------ %
% >> ------------------------ 附录 ------------------------ << %

% % 附录设置
% \newpage
% \appendix
% % chapter 标题自定义设置
% \titleformat{\chapter}[hang]{\normalfont\huge\bfseries\centering}{}{20pt}{}
% \titlespacing*{\chapter}{0pt}{-25pt}{8pt} % 控制上方空白的大小
% % section 标题自定义设置 
% \titleformat{\section}[hang]{\normalfont\centering\Large\bfseries}{\thesection}{8pt}{}






% % 附录 B
% \chapter*{附录 B. 代码}\addcontentsline{toc}{chapter}{附录 B. 代码}   
% \thispagestyle{fancy} 
% \setcounter{section}{0}   
% \renewcommand\thesection{B.\arabic{section}}   
% \renewcommand{\thefigure}{B.\arabic{figure}} 
% \renewcommand{\thetable}{B.\arabic{table}}

% 注意：listing环境中手动输入的代码需要顶格写




% >> ------------------------ 附录 ------------------------ << %
% ------------------------------------------------------------ %

\end{document}
